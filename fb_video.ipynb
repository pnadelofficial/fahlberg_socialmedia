{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_request_url': '1335918663656069',\n",
       " 'post_url': 'https://m.facebook.com/1335918663656069'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download comments for a public Facebook post.\n",
    "\"\"\"\n",
    "\n",
    "import facebook_scraper as fs\n",
    "from facebook_scraper import *\n",
    "\n",
    "set_user_agent(\n",
    "    \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\")\n",
    "\n",
    "# get POST_ID from the URL of the post which can have the following structure:\n",
    "# https://www.facebook.com/USER/posts/POST_ID\n",
    "# https://www.facebook.com/groups/GROUP_ID/posts/POST_ID\n",
    "POST_ID = \"1335918663656069\"\n",
    "\n",
    "# number of comments to download -- set this to True to download all comments\n",
    "MAX_COMMENTS = 100\n",
    "\n",
    "# get the post (this gives a generator)\n",
    "gen = fs.get_posts(\n",
    "    post_urls=[POST_ID],\n",
    "    options={\"comments\": MAX_COMMENTS, \"progress\": True}\n",
    ")\n",
    "\n",
    "# take 1st element of the generator which is the post we requested\n",
    "post = next(gen)\n",
    "post\n",
    "# # extract the comments part\n",
    "# comments = post['comments_full']\n",
    "\n",
    "# # process comments as you want...\n",
    "# for comment in comments:\n",
    "\n",
    "#     # e.g. ...print them\n",
    "#     print(comment)\n",
    "\n",
    "#     # e.g. ...get the replies for them\n",
    "#     for reply in comment['replies']:\n",
    "#         print(' ', reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "Content Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m set_user_agent(\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mMozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m t \u001b[39m=\u001b[39m get_posts(\u001b[39m'\u001b[39m\u001b[39mLa Lima de Todos\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[39mnext\u001b[39;49m(t)\n",
      "File \u001b[0;32m~/miniconda3/envs/sm_scrape/lib/python3.9/site-packages/facebook_scraper/facebook_scraper.py:1114\u001b[0m, in \u001b[0;36mFacebookScraper._generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m counter \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mcount(\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m page_limit \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mrange\u001b[39m(page_limit)\n\u001b[1;32m   1113\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mStarting to iterate pages\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1114\u001b[0m \u001b[39mfor\u001b[39;00m i, page \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(counter, iter_pages_fn()):\n\u001b[1;32m   1115\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mExtracting posts from page \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, i)\n\u001b[1;32m   1116\u001b[0m     \u001b[39mfor\u001b[39;00m post_element \u001b[39min\u001b[39;00m page:\n",
      "File \u001b[0;32m~/miniconda3/envs/sm_scrape/lib/python3.9/site-packages/facebook_scraper/page_iterators.py:87\u001b[0m, in \u001b[0;36mgeneric_iter_pages\u001b[0;34m(start_url, page_parser_cls, request_fn, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRequesting page from: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, next_url)\n\u001b[0;32m---> 87\u001b[0m     response \u001b[39m=\u001b[39m request_fn(next_url)\n\u001b[1;32m     88\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/sm_scrape/lib/python3.9/site-packages/facebook_scraper/facebook_scraper.py:925\u001b[0m, in \u001b[0;36mFacebookScraper.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mif\u001b[39;00m title:\n\u001b[1;32m    924\u001b[0m     \u001b[39mif\u001b[39;00m title\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m not_found_titles:\n\u001b[0;32m--> 925\u001b[0m         \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mNotFound(title\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    926\u001b[0m     \u001b[39melif\u001b[39;00m title\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    927\u001b[0m         \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnexpectedResponse(\u001b[39m\"\u001b[39m\u001b[39mYour request couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be processed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotFound\u001b[0m: Content Not Found"
     ]
    }
   ],
   "source": [
    "from facebook_scraper import get_posts\n",
    "from facebook_scraper import *\n",
    "\n",
    "set_user_agent(\n",
    "    \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\")\n",
    "t = get_posts('La Lima de Todos')\n",
    "next(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('sm_scrape')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "415a44414f563ecf9ba46ff5e4135ffc88be5696b74300382629a535b8530d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
